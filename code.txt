# Importing necessary libraries
import tensorflow as tf
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Normalization, Dense, InputLayer, LeakyReLU, BatchNormalization, Reshape
from tensorflow.keras.losses import MeanSquaredError, Huber, MeanAbsoluteError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers.legacy import Adam
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder

# Load the dataset
data = pd.read_csv("/content/real_data.csv")
data_original = data

# Split data into inputs (X) and outputs (y)
X = data.iloc[:, 0:1]  # Select the first column ('operating_frequency') using .iloc for integer-location based indexing
y = data.iloc[:, 1:]   # Select all columns except the first using .iloc

# Normalize the data
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()
X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Define the latent dimension for noise
latent_dim = X_scaled.shape[1]

from tensorflow.keras.layers import Dropout
from tensorflow.keras.models import Sequential # Import the Sequential class
from tensorflow.keras.layers import Dropout

def build_generator(latent_dim, output_dim):
    model = Sequential()
    model.add(Dense(256, input_dim=latent_dim))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dropout(0.3))

    model.add(Dense(256))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dropout(0.3))

    model.add(Dense(256))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dropout(0.3))

    model.add(Dense(output_dim, activation='linear'))  # Output shape adjusted for patch dimensions
    return model

generator = build_generator(latent_dim, y_scaled.shape[1])
generator.summary()

def build_discriminator(input_shape):
    model = Sequential()
    model.add(Dense(512, input_dim=input_shape))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(256))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(1, activation='sigmoid'))  # Use sigmoid for binary classification
    return model

from tensorflow.keras.optimizers import Adam # Import Adam from tensorflow.keras.optimizers

input_shape = y_scaled.shape[1]
discriminator = build_discriminator(input_shape)
discriminator.compile(loss='binary_crossentropy',
                      optimizer=Adam(learning_rate=0.0002, beta_1=0.5), # Use the correct Adam import
                      metrics=['accuracy'])

# Build the GAN model
discriminator.trainable = False
GAN = Sequential()
GAN.add(generator)
GAN.add(discriminator)
GAN.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5)) # Use the correct Adam import

def train_gan(gan, generator, discriminator, X_train, y_train, epochs, batch_size):
    d_losses = []
    g_losses = []
    generator_mse = []

    for epoch in range(epochs):
        # Generate fake antenna parameters
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        gen_antenna_params = generator.predict(noise)

        # Get a random set of real antenna parameters
        idx = np.random.randint(0, y_train.shape[0], batch_size)
        real_antenna_params = y_train[idx]

        # Create labels for real and fake data
        real_labels = np.ones((batch_size, 1)) * 0.9  # Label smoothing
        fake_labels = np.zeros((batch_size, 1))

        # Train the discriminator
        d_loss_real = discriminator.train_on_batch(real_antenna_params, real_labels)
        d_loss_fake = discriminator.train_on_batch(gen_antenna_params, fake_labels)
        d_loss = 0.5 * np.add(d_loss_real[0], d_loss_fake[0])

        # Train the generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        g_loss = gan.train_on_batch(noise, real_labels)

        # Save the losses
        d_losses.append(d_loss)
        g_losses.append(g_loss)

        # Calculate generator MSE
        mse = np.mean(np.square(gen_antenna_params - real_antenna_params))
        generator_mse.append(mse)

        # Print the progress
        if epoch % 100 == 0:
            print(f"{epoch}/{epochs}, D Loss: {d_losses[-1]}, G Loss: {g_losses[-1]}, MSE: {mse}")

    return d_losses, g_losses, generator_mse

# Example usage
epochs = 2000
batch_size = 64
d_losses, g_losses, generator_mse = train_gan(GAN, generator, discriminator, X_scaled, y_scaled, epochs, batch_size)

# Import the matplotlib.pyplot module
import matplotlib.pyplot as plt
# Plot the discriminator and generator losses
plt.figure(figsize=(10, 5))
plt.plot(d_losses, label="Discriminator Loss")
plt.plot(g_losses, label="Generator Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.title("GAN Losses Over Epochs")
plt.show()

# Plot the generator MSE
plt.figure(figsize=(10, 5))
plt.plot(generator_mse, label="Generator MSE")
plt.xlabel("Epochs")
plt.ylabel("MSE")
plt.legend()
plt.title("Generator MSE Over Epochs")
plt.show()

# Use the trained generator to predict antenna parameters for a given operating frequency
def predict_antenna_params(generator, frequency):
    frequency_scaled = scaler_X.transform([[frequency]])
    antenna_params_scaled = generator.predict(frequency_scaled)
    antenna_params = scaler_y.inverse_transform(antenna_params_scaled)
    return antenna_params

# Combine losses into a DataFrame
loss_data = {
    'Epoch': list(range(1, epochs + 1)),
    'Discriminator_Loss': d_losses,
    'Generator_Loss': g_losses,
    'Generator_MSE': generator_mse
}

loss_df = pd.DataFrame(loss_data)

# Save to CSV
csv_file_path = '/content/gan_losses.csv'
loss_df.to_csv(csv_file_path, index=False)

# Step 1: Generate a batch of data
def predict_antenna_params(generator, frequency, scaler_X, scaler_y, num_samples=100):
    # Reshape the input to match the generator's expected input shape
    frequency_scaled = scaler_X.transform([[frequency]])
    frequency_scaled = np.repeat(frequency_scaled, num_samples, axis=0) # Repeat the input for num_samples times

    antenna_params_scaled = generator.predict(frequency_scaled)
    antenna_params = scaler_y.inverse_transform(antenna_params_scaled)
    return antenna_params

# Example frequency for which to generate data
example_frequency = 15  # Replace with the desired frequency

# Generate the antenna parameters
generated_data = predict_antenna_params(generator, example_frequency, scaler_X, scaler_y)

# Convert the generated data to a DataFrame
generated_df = pd.DataFrame(generated_data, columns=["patch_width", "patch_length"])
